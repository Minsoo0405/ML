{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 흐름\n",
    "\n",
    "1. ML -> sklearn -> MLP\n",
    "2. DL -> tensorflow(google) -> Text\n",
    "      -> pytorch(facebook) -> image\n",
    "3. 미세조정을 통해 Fine-Tunning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 딥러닝\n",
    "- 정의: 머신러닝 알고리즘 중에 인공 신경망 구조를 기반으로 학습하는 방법\n",
    "    - 인공신경망(ANN)\n",
    "        - 정의\n",
    "            - Artificial Neural Network\n",
    "            - 뇌에 있는 생물학적 뉴런의 네트워크에서 영감을 받은 머신러닝 모델\n",
    "            - 핵심: 경사하강법, 오차역전파\n",
    "        - 탄생 및 발전\n",
    "            - 연결주의자\n",
    "                : 임의 이진수를 계산하는(AND, OR, NOT) 전기회로제시, 설계된 동작만을 수행, 변경불가\n",
    "            - 단층 퍼셉트론\n",
    "                : 학습방법제시(오차를 줄이도록 연결 강도 변경)했으나 구현 못함, XOR 해결못함\n",
    "            - 다층 퍼셉트론\n",
    "                : 은닉층을 제시, XOR를 해결. 단, 오류를 줄이면서 학습하는 기능 구현 못함\n",
    "            - 오차역전파\n",
    "                : 다층 퍼셉트론의 학습 방법 제시. (단점: 사라지는 경사)\n",
    "    - 딥러닝의 작동 원리 이해하기\n",
    "        - 머신러닝이 많은 입력과 타깃의 샘플을 관찰하면서 입력울 타깃에 매핑하는 것\n",
    "        - 다른 머신러닝 알고리즘들처럼 딥러닝 역시 데이터를 입력받아 예측을 출력\n",
    "        - 층에서 입력 데이터가 처리되는 상세 내용은 일련의 숫자로 이루어진 층의 가중치(weight)에 저장되어 있음\n",
    "        - 학습은 주어진 입력을 정확한 타깃에 매핑하기 위해 신경망의 모든 층에 있는 가중치 값을 찾는 것을 의미함\n",
    "\n",
    "    - 요약\n",
    "        - 딥러닝은 머신러닝 알고리즘이라는 기본 개념 안에 뇌가 사물을 이해하는 과정(CNN), 뇌가 문맥을 이해하는 과정(RNN) 등, 각 상황에 따라 뇌가 이해하는 과정을 형상화한 새부적인 딥러닝 알고리즘을 가지고 있음.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 단층 퍼셉트론 - 학습할 수 있는 모델\n",
    "- 정의\n",
    "    - 뉴런 하나로 여러 개의 입력을 받아 하나의 신호를 출력하는 이론\n",
    "    - 가장 기초가 되는 인공 신경망 구조 중 하나\n",
    "- 퍼섭트론의 작동 원리\n",
    "    - ex) 두 개의 입력(전기입력)이 있을 때 하나의 뉴런으로 두 개의 입력을 계산한 뒤, 최종 결과값으로 0 또는 1을 출력하는 모델\n",
    "    - 퍼셉트론은 X와 가중치 w(연결강도)를 곱한 값을 모두 더하여 하나의 값(y)로 만들어 낸 후, 이를 임계값와 비교하여 0 또는 1을 출력함 => 시그모이드함수의 개념\n",
    "    - 활성화함수: 신경망에서 만들어진 값을 적절한 출력값으로 변환시키는 함수\n",
    "- 요약\n",
    "    - 여러 개의 신호를 입력으로 받아 하나의 값을 출력\n",
    "    - x는 입력, y는 출력, w는 가중치\n",
    "    - x와 가중치w를 곱한값을 모두 더하여 하나의 값(y)로 만들어냄\n",
    "- AND 연산을 하는 퍼셉트론의 예\n",
    "    - 편향값(bias)은 모델이 좀 더 쉽고 빠르게 목적을 달성하는데 도움을 줌"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다층 퍼셉트론\n",
    "\n",
    "- 정의\n",
    "    - MLP: Multi Level Perceptron\n",
    "    - 다층 구조의 퍼셉트론은 더 많은 수의 연결이 더 많은 단계로 연결되어 복잡한 동작을 할 수 있음\n",
    "    \n",
    "- 퍼셉트론이 XOR 문제를 풀 수 있게 만드는 방법\n",
    "    - OR회로, NAND(Not AND)회로, AND회로를 조합하여 만들수 있다.\n",
    "\n",
    "- 심층 신경망(DNN: Deep Neural Network)\n",
    "    - 다층 퍼셉트론 구조에서 특히 은닉층이 2개 이상인 경우를 심층 신경망이라고 한다.\n",
    "    - 심층 신경망 구조를 통해ㅑ서 학습을 수행하는 것을 심층학습, 즉 딥러닝이라고 한다.\n",
    "\n",
    "- 🌟🌟🌟 심층신경망 구조 이해\n",
    "    - 입력층 \n",
    "        : 입력 데이터가 그대로 통과하는 층이므로, 입력층 노드의 개수는 입력 특성의 개수와 동일하게 자동으로 지정된다\n",
    "    - 출력층\n",
    "        ; 출력은 클래스 분류 결과이므로, 출력층 노드의 개수는 분류 대상 클래스의 개수와 동일하게 자동으로 지정된다.\n",
    "\n",
    "    - 은닉층(hidden layer)\n",
    "        - 은닉층 1개에 존재하는 노드의 개수는 경험적으로 100 또는 200을 기준으로 상황에 따라 조절한다\n",
    "        - 은닉층들의 층 수가 늘어난다고 해서 반드시 학습 효과가 향상되는 것은 아니다 \n",
    "        - 은닉층의 모든 노드들은 하위층의 모든 입력을 받는다\n",
    "        - 은닉층의 모든 녿드들은 사우이층의 모든 입력으로 출력을 내보낸다\n",
    "\n",
    "- 다층 퍼셉트론과 학습\n",
    "    - 오차 계산 방법\n",
    "        - 학습이란 출력값과 정답을 비교하여 오차를 구하고 그 오차를 줄이도록 인공지능 모델을 나가는 과정\n",
    "        - 데이터와 모델의 특징에 따라 적합한 오차 공식을 적용하는 것이 필요\n",
    "            - 이항교차 엔트로피: 오차를 0 또는 특정값으로 나누어 부여\n",
    "            - 카테고리컬 크로스 엔트로지: 여러 값 중 하나를 예측하는 모델에서\n",
    "            -평균오차계산법: 회귀 예측모델에서 특정값을 예측하는 경우\n",
    "    - 오차 줄이기\n",
    "        - 인공 신경망의 핵심으로 오차를 줄이기 위해서는 각 뉴런에 전달하는 신호의 세기를 조절해야함\n",
    "        - 전달하는 신호의 세기를 조절하는 방법: 가중치의 값을 수정하는 것\n",
    "        - 가중치 수정 방법\n",
    "            - 경사하강법 계산법\n",
    "                : 오차그래프(가중치 VS 오차)에서 오차를 최소로 하는 가중치 값으로 가중치를 이동\n",
    "            - 옵티마이저: 경사하강법에 따라 가중치를 이동시킬 때 얼마만큼 이동시키는 것이 가장 좋은 것인지 판별하는 방법(Adam, SGD 등)\n",
    "            - 오차 역전파법(Back Propagation, ChainRule): 오차가 있으면 마지막부터 처음까지 되돌아가면서 경사하강법을 사용하여 각각의 가중치 값을 수정해 나감.\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
