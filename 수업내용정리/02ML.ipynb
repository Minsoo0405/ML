{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀이란?\n",
    "\n",
    "1. 회귀이란? \n",
    " - 데이터의 값은 평균과 같은 기존의 경향으로 돌아가려는 경향이 있다는 것\n",
    " - 여러 변수들 간의 상관관계를 파악하여 어떤 특정 변수의 값을 다른 변수들의 값을 이용하여 설명, 예측하는 수리식을 찾는 방법\n",
    "    (종속변수 <-> 독립변수)\n",
    " - 종속변수와 독립변수간의 회귀식을 찾는 것\n",
    "\n",
    "2. 회귀계수이란?\n",
    " - coefficient\n",
    " - y에 미치는 독립변수 x의 영향력의 크기\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 분석 유형\n",
    "\n",
    "1. 회귀 분석의 유형\n",
    "    : 변수의 개수 및 계수의 형태에 따라 구분한다.\n",
    "\n",
    "    1) 독립 변수의 개수에 따라\n",
    "        1-1) 단순회귀분석: 독립변수가 1개인 경우, 단일 회귀분석이라고도 함.\n",
    "        1-2) 다중회귀분석: 독립변수가 여러 개인 경우\n",
    "    2) 회귀 계수의 형태에 따라\n",
    "        2-1) 선형: 계수를 선형 결합으로 표현할 수 있는 경우\n",
    "        2-2) 비선형: 계수를 선형 결합으로 표현할 수 없는 경우\n",
    "    3) 종속 변수의 개수에 따라\n",
    "        3-1) 단변량 회귀모델: 종속변수가 1개인 경우\n",
    "        3-2) 다변량 회귀모델: 종속변수가 여러 개인 경우"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀\n",
    "\n",
    "1. 선형 회귀란?\n",
    "    - 종속 변수가 독립변수와 회귀계수의 선형 조합으로 표현 가능한 경우\n",
    "    - 파라미터(계수)에 대한 선형성만을 가정함\n",
    "    - 독립변수 X와 종속변수 Y 간의 상호 연관성 정도를 파악하기 위한 분석 기법\n",
    "    - 변수 간의 인과관계를 분석할 때 많이 사용\n",
    "\n",
    "2. 단순 선형 회귀(Simple Linear Regression)\n",
    "    1) 정의\n",
    "        - 독립변수가 1개이고, 종속변수도 1개\n",
    "        - 독립변수와 종속변수 간의 관계를 선형적으로 파악하는 회귀 방식\n",
    "    2) 회귀 계수(coefficient)\n",
    "        - 독립변수가 종속변수에 끼치는 영향력(설명력)의 정도, 직선의 기울기\n",
    "    3) 절편(intercept)\n",
    "        - 독립변수가 0일때, 상수값\n",
    "\n",
    "3. 오차와 손실함수(Cost Function)\n",
    "    - 기울기와 절편의 값에 따라 여러 개의 직선이 있을 수 있음\n",
    "    - 가장 데이터를 잘 설명하는 직선의 방정식을 추정\n",
    "    - 실제 y값과 예측값 y^의 차\n",
    "    - 오차의합을 가장 적게 만드는 회귀계수와 절편을 찾는게 가장 좋은 회귀식을 찾는 방법\n",
    "\n",
    "    1) 오차\n",
    "        - 평균 제곱 오차(MSE: Mean Square Error)\n",
    "        - 평균 절대값 오차(MAE: Mean Absolute Error)\n",
    "        - 평균 제곱근 오차(RMSE: Root Mean Square Error)\n",
    "    2) 잔차 제곱 오차 함수\n",
    "        - 잔차(residual) / 오차(error)\n",
    "        - 잔차 제곱합(RSS: Resiual Sum of Squares): 모든 데이터 점의 잔차를 제곱하여 합한 것\n",
    "    3) 손실함수(loss function) / 비용함수(cost function)\n",
    "        - 회귀계수를 추정할 때 손실을 최소화할 목적으로 사용하는 함수\n",
    "        - 회귀에서는 손실함수 또는 비용함수를 어떤 것을 쓰는가? -> RSS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 계수 탐색(선형 방정식 찾기)\n",
    "\n",
    "1. 행렬방정식\n",
    "\n",
    "2. 경사하강법(아무렇게나)\n",
    "    : 반복적인 계산에 의해 근사값을 구하는 수치 계산법\n",
    "\n",
    "3. 최소제곱법(Ordianary least suquares)\n",
    "    1) 정의 \n",
    "        - 학습에 사용되는 각 데이터 인스턴스 x를 i번째 행으로 하는 행렬을 X라고 정의할 때 최적의 파라미터\n",
    "    2) 코드\n",
    "        sklearn.linear_model.LinearRegression()\n",
    "    3) \n",
    "        - 특성의 개수(입력의 차원)가 많을수록 느려지고 \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정 계수\n",
    "\n",
    "1. 결정계수이란?\n",
    "\n",
    "    : Coefficient of Determination, 개체(종속변수)가 가지는 총 변량 중 회귀식이 설명(차지)하는 변량의 비율\n",
    "\n",
    "    1) 개체 y가 가지는 총 변량\n",
    "        - 실제값 y와 모든 y값의 평균의 차\n",
    "        - 회귀식이 차지하는 변량(= 예측값의 분산) : |예측값 y와 모든 y의 평균의 차|\n",
    "        - (= 실제값의 분산) : |실제값 y와 모든|\n",
    "\n",
    "    2) 결정계수(R^2)\n",
    "        - (에측값의 분산) / (실제값의 분산)\n",
    "        - 모델이 얼마나 종속변수를 잘 서명하는가에 관한 지표\n",
    "        - 0 <= R^2 <= 1: 최소제곱법을 이요한 선형회귀에서는 예측값과 실제값의 상관계수를 제곱한 수치가 결정계수와 같아진다\n",
    "        - 만약 모델의 잔차가 매우 큰 경우 결정계수는 마이너스가 나올 수 있다.\n",
    "    \n",
    "    3) 해석\n",
    "        - 결정계수의 값은 0 <= R^2 <= 1이며, 1에 가까울수록 설명력이 강하고 0에 가까울수록 설명력이 약하다\n",
    "\n",
    "    4) 코드\n",
    "        : sklearn.metrics.r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_true = [1,2,3]\n",
    "y_pred = [1,2,3]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런의 회귀 분석 평가지표\n",
    "\n",
    "|지표|모듈 및 함수|설명|식|\n",
    "|||||\n",
    "|MAE|metrics.mean_absolute_error|||\n",
    "|MSE||||\n",
    "|RMSE||||\n",
    "|R^2||||"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀 이론 정리\n",
    "\n",
    "1. 머신렁닝의 개념으로 해석하는 선형회귀\n",
    "2. 가설함수: 최적의 회귀선\n",
    "3. 손실함수: 예측값과 실제값의 차이(오차)의 합(평균)\n",
    "4. 회귀계수를 찾는 방법: 최소 제곱법, 경사하강법\n",
    "5. 회귀모델 평가지표\n",
    "6. 모델 성능 평가"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순선형회귀 머신러닝 구현(스탯츠모델)\n",
    "\n",
    "1. 선형 회귀모델 객체 생성\n",
    "    1) 스탯츠 모델\n",
    "        lr = sm.OLS(y_train, X_train)\n",
    "\n",
    "2. 모델 객체에 대한 학습 수행\n",
    "    - 선형 회귀를 수행할 객체에 대하여 fit()메소드를 이용하여 학습을 수행\n",
    "    - 회귀식 구현: 회귀계수, 절편\n",
    "\n",
    "3. 모델의 평가: summary()함수를 사용하여 추정 결과를 표시함\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중선형 회귀\n",
    "\n",
    "    1. 정의\n",
    "        - 단순 선형회귀 알고리즘에서 독립변수의 갯수를 확장시킨 경우\n",
    "        - 독립변수가 2개 이상이고 종속변수는 1개인 경우, 독립변수들과 종속변수간의 관계를 선혀엊ㄱ으로 파악하는 선형행렬\n",
    "        - 단순 선형 회귀에서 독립변수의 개수만 늘어난 것이다.\n",
    "        - 단, 독립변수의 수가 않아지므로 이로 인해 발생할 수있는 경우들을 고려해서 적절한 조치를 취해야 한다.\n",
    "\n",
    "    2. 독립변수들의 최초 선택\n",
    "        - 회귀분석의 목적: 종속 변수를 가장 잘 설명하는 독립변수들의 성향/특징들을 찾아내어 이를 기반으로 기존의 자료를 설명하거나 새로운 결과를 예측하는 것"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 선현회귀 머신러닝 구현(사이킷런)\n",
    "\n",
    "1. 알고리즘: 최소제곱법(OLS)\n",
    "    1) 데이터 수집 및 탐색  => 변수간의 상관관계 분석\n",
    "    2) 모델 클래스 선택\n",
    "    3) 모델 객체 생성\n",
    "    4) 모델에 사용할 특성 데이터셋 및 타깃 데이터셋 준비\n",
    "    5) 객체에 대해 학습 수행: fit()\n",
    "    6) 실행 객체 또는 추정된 모델에 대해 예측 수행\n",
    "    7) 분석 결과를 평가: MSE, RMSE, R2, Adj_R2수정된 결정계수   => 다중 선형회귀 평가지표"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 탐색적 데이터 분석\n",
    "\n",
    "1. 정의\n",
    "    - 수집한 데이터를 분석하기 전에 데이터의 특성을 관찰하고 이해하는 단계\n",
    "    - 원 데이터(Raw Data) 를 대상으로 유연하게 데이터를 탐색하고, 데이터의 특징과 구조에 대한 정보를 획득함.\n",
    "\n",
    "2. 목적\n",
    "    - 데이터 종류의 확인과 데이터 간의 관계에 대한 더 나은 이해를 목적으로 함\n",
    "    - 데이터를 살펴서 명백한 오류를 제거하고 데이터 내의 패턴을 이해하고 이상치를 감지하며 변수 간의 맥ㄹ락을 찾아냄\n",
    "\n",
    "3. EDA 도구\n",
    "    - 요약 통계 및 각 독립변수에 대한 일변량 시각화\n",
    "\n",
    "4. 분석 방법\n",
    "    - 전체적인 데이터 살펴보기\n",
    "    - 이상치(Outlier) 분석\n",
    "    - 속성간의 관계 분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공분산\n",
    "\n",
    "1. 정의\n",
    "    - Covariance\n",
    "    - 두 데이터간의 관계를 지표로 표현하기 위해 공분산 및 상관관계에 대한 이해가 필요하다\n",
    "\n",
    "    1) 산점도 분석\n",
    "\n",
    "2. 계산코드\n",
    "\n",
    "    1. \n",
    "\n",
    "3. 상관 관계\n",
    "    - 두 변수x와 y사이의 관련 강도\n",
    "    - 밀집도를 측정\n",
    "    - 변수들이 같은 방향으로 움직이려는 경향\n",
    "    - 높은 상관성을 가질 때 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관 분석\n",
    "\n",
    "1. 상관 분석\n",
    "\n",
    "2. 상관 계수\n",
    "    - 각 데이터의 표준편차로 나누어 단위에 읜존하지 않는 지표\n",
    "    - (-1)에서 1사이의 값을 가짐\n",
    "    - 0 ~ 0.2 : 상관관계 거의 없음 / 0.2 ~ 0.4: 약한 상관관계가 있음 / 0.4 ~ 0.6:\n",
    "\n",
    "3. 상관 분석 시각화\n",
    "\n",
    "    1) 산점도\n",
    "    2) 히트맵\n",
    "\n",
    "4. 다중 공선성 문제\n",
    "    - 다수의 독립변수가 서로 강한상관관계가 나타나는것을 다중 공선성이라고 한다.\n",
    "        (즉, 어떤 독립변수의 값이 독ㄹ립적이지 않고 다른 독립변수들의 값에 의해서 결정된다는 것)\n",
    "    - 독립변수들끼리의 상관계수 R이 지나치게 높으면(아무리 설명력이 좋다고 하더라도) 회귀 모형이 유의미하다고 보기 어렵다.\n",
    "        (회귀계수의 추정의 오류가 발생한다)\n",
    "    - 회귀분석의 전제 중 하나인 독립성을 가진 돍립변수들이 각각 종속변수의 분산을 설명하여야 영향력을 예측할 수 있는데, 하나로 봐도 무방한 독립변수가 사용되면 설명력을 떨어뜨리고 표준오차를 증가시킨다.\n",
    "    - 따라서 상관계수가 높은 변수들ㅇ르 삭제하거나, 주성분 분석(PCA) 기법 등을 이용하여 의존적인 성분을 제거\n",
    "\n",
    "5. 수정된 결정 계수(Ajusted R^2)\n",
    "    - 독립변수의 개수가 많아질수록 그 변수들이 종속변수에 끼치는 영향력은 늘어나게 된다.\n",
    "        (즉, 독립변수가 많을 수록 종속변수에 대한 섬령력은 증가한다.)\n",
    "    - 따라서 다중 회구 분석에서는 결정계숙 R^2의 값이 단순 회귀보다 높게 나오는 경향이 있고, 이는 독립변수의 수가 많아질수록 더욱 증가한다.\n",
    "    - 이를 보완하여 수정된 결정계수를 도입했으며, 다중회귀에서는 일반적으로 수정 결정계수의 값을 이용하여 분석결과를 판단한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29022363fef606f9f23df6f4a22f2b4728bceb42fab3e5e3f1a324182233d5f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
